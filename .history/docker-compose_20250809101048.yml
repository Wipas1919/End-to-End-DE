version: '3.8'

# On-Premise Data Platform - Docker Compose Configuration
# 
# Team Responsibilities:
# - Data Platform Team: Manages all application services, databases, and monitoring
# - Infrastructure Team: Manages underlying infrastructure (servers, network, storage)
#
# Collaboration Points:
# - Resource requirements provided to Infrastructure team
# - Network configuration coordinated with Infrastructure team
# - Security requirements defined by Data Platform team, implemented by Infrastructure team

services:
  # =============================================================================
  # DATABASE & STORAGE LAYER (Data Platform Team)
  # =============================================================================
  
  mysql:
    image: mysql:8.0
    container_name: data-platform-mysql
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: data_platform
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql
    networks:
      - data-network
    # Resource requirements for Infrastructure team:
    # - CPU: 2 cores
    # - RAM: 8GB
    # - Storage: 200GB SSD

  minio:
    image: minio/minio:latest
    container_name: data-platform-minio
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    networks:
      - data-network
    # Resource requirements for Infrastructure team:
    # - CPU: 2 cores
    # - RAM: 4GB
    # - Storage: 500GB SSD

  influxdb:
    image: influxdb:2.0
    container_name: data-platform-influxdb
    environment:
      DOCKER_INFLUXDB_INIT_MODE: setup
      DOCKER_INFLUXDB_INIT_USERNAME: ${INFLUXDB_USERNAME}
      DOCKER_INFLUXDB_INIT_PASSWORD: ${INFLUXDB_PASSWORD}
      DOCKER_INFLUXDB_INIT_ORG: data_platform
      DOCKER_INFLUXDB_INIT_BUCKET: iot_data
    ports:
      - "8086:8086"
    volumes:
      - influxdb_data:/var/lib/influxdb2
    networks:
      - data-network
    # Resource requirements for Infrastructure team:
    # - CPU: 2 cores
    # - RAM: 4GB
    # - Storage: 200GB SSD

  # =============================================================================
  # PIPELINE & OPERATION LAYER (Data Platform Team)
  # =============================================================================
  
  # Primary ETL Engine
  windmill:
    image: windmilllabs/windmill:latest
    container_name: data-platform-windmill
    environment:
      BASE_URL: http://localhost:8000
      DATABASE_URL: postgresql://windmill:windmill@windmill-db/windmill
      RUST_LOG: info
    ports:
      - "8000:8000"
    volumes:
      - windmill_data:/app/data
      - ./windmill:/app/windmill
    depends_on:
      - windmill-db
    networks:
      - data-network
    # Resource requirements for Infrastructure team:
    # - CPU: 4 cores
    # - RAM: 8GB
    # - Storage: 100GB SSD

  windmill-db:
    image: postgres:13
    container_name: data-platform-windmill-db
    environment:
      POSTGRES_USER: windmill
      POSTGRES_PASSWORD: windmill
      POSTGRES_DB: windmill
    volumes:
      - windmill_db_data:/var/lib/postgresql/data
    networks:
      - data-network
    # Resource requirements for Infrastructure team:
    # - CPU: 1 core
    # - RAM: 2GB
    # - Storage: 50GB SSD

  # Alternative ETL Engine (Not in Use)
  airflow-webserver:
    image: apache/airflow:2.7.1
    container_name: data-platform-airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    ports:
      - "8080:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    depends_on:
      - postgres
      - redis
    networks:
      - data-network
    profiles:
      - alternative

  airflow-scheduler:
    image: apache/airflow:2.7.1
    container_name: data-platform-airflow-scheduler
    environment:
      AIRFLOW__CORE__EXECUTOR: CeleryExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@postgres/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://:@redis:6379/0
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    depends_on:
      - postgres
      - redis
    networks:
      - data-network
    profiles:
      - alternative

  postgres:
    image: postgres:13
    container_name: data-platform-postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - data-network
    profiles:
      - alternative

  redis:
    image: redis:latest
    container_name: data-platform-redis
    networks:
      - data-network
    profiles:
      - alternative

  # =============================================================================
  # SECURITY & ACCESS LAYER (Data Platform Team)
  # =============================================================================
  
  kong:
    image: kong:latest
    container_name: data-platform-kong
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: kong-database
      KONG_PG_USER: kong
      KONG_PG_PASSWORD: kong
      KONG_PG_DATABASE: kong
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      KONG_ADMIN_LISTEN: 0.0.0.0:8001
      KONG_ADMIN_GUI_URL: http://localhost:8002
    ports:
      - "8000:8000"
      - "8443:8443"
      - "8001:8001"
      - "8444:8444"
    depends_on:
      - kong-database
    networks:
      - data-network
    # Resource requirements for Infrastructure team:
    # - CPU: 1 core
    # - RAM: 2GB
    # - Storage: 20GB SSD

  kong-database:
    image: postgres:13
    container_name: data-platform-kong-database
    environment:
      POSTGRES_USER: kong
      POSTGRES_DB: kong
      POSTGRES_PASSWORD: kong
    volumes:
      - kong_data:/var/lib/postgresql/data
    networks:
      - data-network
    # Resource requirements for Infrastructure team:
    # - CPU: 1 core
    # - RAM: 2GB
    # - Storage: 50GB SSD

  # =============================================================================
  # GOVERNANCE & MONITORING LAYER (Data Platform Team)
  # =============================================================================
  
  open-metadata:
    image: openmetadata/openmetadata:latest
    container_name: data-platform-openmetadata
    environment:
      MYSQL_HOST: mysql
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
      MYSQL_DATABASE: data_platform
    ports:
      - "8585:8585"
    depends_on:
      - mysql
    networks:
      - data-network
    # Resource requirements for Infrastructure team:
    # - CPU: 2 cores
    # - RAM: 4GB
    # - Storage: 50GB SSD

  # Monitoring Stack
  prometheus:
    image: prom/prometheus:latest
    container_name: data-platform-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - data-network
    # Resource requirements for Infrastructure team:
    # - CPU: 1 core
    # - RAM: 2GB
    # - Storage: 100GB SSD

  grafana:
    image: grafana/grafana:latest
    container_name: data-platform-grafana
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - data-network
    # Resource requirements for Infrastructure team:
    # - CPU: 1 core
    # - RAM: 2GB
    # - Storage: 50GB SSD

  # =============================================================================
  # ON-PREMISE VISUALIZATION & APPLICATIONS (Data Platform Team)
  # =============================================================================
  
  streamlit:
    image: python:3.9-slim
    container_name: data-platform-streamlit
    working_dir: /app
    ports:
      - "8501:8501"
    volumes:
      - ./streamlit:/app
    command: >
      bash -c "pip install streamlit pandas numpy matplotlib seaborn plotly
               && streamlit run app.py --server.port=8501 --server.address=0.0.0.0"
    networks:
      - data-network
    # Resource requirements for Infrastructure team:
    # - CPU: 1 core
    # - RAM: 2GB
    # - Storage: 20GB SSD

  # =============================================================================
  # TOOLS & APPLICATION LAYER (Data Platform Team)
  # =============================================================================
  
  portainer:
    image: portainer/portainer-ce:latest
    container_name: data-platform-portainer
    ports:
      - "9000:9000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data
    networks:
      - data-network
    # Resource requirements for Infrastructure team:
    # - CPU: 1 core
    # - RAM: 1GB
    # - Storage: 20GB SSD

  # =============================================================================
  # DATA QUALITY & VALIDATION SERVICE (Data Platform Team)
  # =============================================================================
  
  data-quality:
    image: python:3.9-slim
    container_name: data-platform-data-quality
    working_dir: /app
    volumes:
      - ./data-quality:/app
    command: >
      bash -c "pip install pandas numpy great-expectations sqlalchemy pymysql
               && python data_quality_service.py"
    depends_on:
      - mysql
      - influxdb
    networks:
      - data-network
    # Resource requirements for Infrastructure team:
    # - CPU: 1 core
    # - RAM: 2GB
    # - Storage: 20GB SSD

volumes:
  mysql_data:
  minio_data:
  influxdb_data:
  windmill_data:
  windmill_db_data:
  postgres_data:
  kong_data:
  prometheus_data:
  grafana_data:
  portainer_data:

networks:
  data-network:
    driver: bridge

# =============================================================================
# INFRASTRUCTURE TEAM NOTES
# =============================================================================
#
# Total Resource Requirements:
# - CPU: 16 cores (8 cores for production, 4 cores for development, 4 cores for backup)
# - RAM: 32GB (16GB for production, 8GB for development, 8GB for backup)
# - Storage: 1.5TB (500GB for production, 250GB for development, 1TB for backup)
# - Network: 1Gbps minimum
#
# Network Requirements:
# - Internal subnet: 192.168.1.0/24
# - External access required for Microsoft Fabric integration
# - VPN access for secure remote management
# - Firewall rules for all exposed ports
#
# Security Requirements:
# - SSL certificates for external access
# - Network segmentation
# - Intrusion detection systems
# - Regular security updates
#
# Backup Requirements:
# - Daily automated backups
# - Point-in-time recovery capability
# - Cross-region replication
# - Regular recovery testing
