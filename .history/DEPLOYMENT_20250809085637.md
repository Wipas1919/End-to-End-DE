# On-Premise Data Platform Deployment Guide

## Overview

This guide provides comprehensive instructions for deploying the on-premise data platform with Microsoft Fabric semantics integration. The platform runs entirely on-premise with only the semantic layer leveraging Microsoft Fabric for advanced analytics.

## Architecture Overview

### On-Premise Components
- **Data Storage**: MySQL, InfluxDB, MinIO
- **ETL Processing**: Windmill (Primary), Apache Airflow (Alternative)
- **Monitoring**: Prometheus, Grafana, Open Metadata
- **Security**: Kong API Gateway, Azure AD integration
- **Visualization**: Grafana, Streamlit, Custom dashboards

### Microsoft Fabric Integration
- **Semantic Layer**: Data models, calculated fields, relationships
- **Power BI**: Interactive dashboards with semantic models
- **On-Premises Data Gateway**: Secure connectivity

## Prerequisites

### System Requirements
- **OS**: Linux (Ubuntu 20.04+ recommended) or Windows Server 2019+
- **CPU**: 8+ cores
- **RAM**: 32GB+ 
- **Storage**: 500GB+ SSD
- **Network**: Stable internet connection for Microsoft Fabric integration

### Software Requirements
- Docker Engine 20.10+
- Docker Compose 2.0+
- Git
- Python 3.9+
- Azure CLI (for Microsoft Fabric integration)

### Microsoft Fabric Setup
- Microsoft 365 Business or Enterprise subscription
- Power BI Pro or Premium license
- On-Premises Data Gateway installation

## Installation Steps

### 1. Environment Setup

```bash
# Clone the repository
git clone <repository-url>
cd End-to-end-de

# Create environment file
cp config.env.example config.env
```

### 2. Configuration

Edit `config.env` with your specific values:

```bash
# Database Configuration
MYSQL_ROOT_PASSWORD=your_secure_password
MYSQL_USER=data_user
MYSQL_PASSWORD=your_secure_password

# MinIO Configuration
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=your_secure_password

# InfluxDB Configuration
INFLUXDB_USERNAME=admin
INFLUXDB_PASSWORD=your_secure_password

# Monitoring Configuration
GRAFANA_PASSWORD=your_secure_password

# Airflow Configuration (if using alternative)
AIRFLOW_FERNET_KEY=your_fernet_key
```

### 3. Microsoft Fabric Integration Setup

#### Install On-Premises Data Gateway

```bash
# Download and install On-Premises Data Gateway
# Follow Microsoft's official installation guide
# https://docs.microsoft.com/en-us/data-integration/gateway/service-gateway-install
```

#### Configure Data Gateway

1. **Register Gateway**:
   - Open Power BI Service
   - Go to Settings > Manage gateways
   - Add new gateway
   - Follow registration process

2. **Configure Data Sources**:
   - Add MySQL connection
   - Add InfluxDB connection
   - Configure authentication

3. **Set Up Data Refresh**:
   - Configure scheduled data refresh
   - Set up incremental refresh policies

### 4. Platform Deployment

#### Start Core Services

```bash
# Start all services
docker-compose up -d

# Check service status
docker-compose ps

# View logs
docker-compose logs -f
```

#### Start Alternative ETL (Optional)

```bash
# Start Apache Airflow as alternative
docker-compose --profile alternative up -d airflow-webserver airflow-scheduler
```

### 5. Service Verification

#### Check Service Health

```bash
# Database connectivity
docker exec data-platform-mysql mysql -u root -p -e "SELECT 1;"

# MinIO console
# Access: http://localhost:9001
# Username: minioadmin
# Password: your_configured_password

# Windmill ETL
# Access: http://localhost:8000

# Grafana monitoring
# Access: http://localhost:3000
# Username: admin
# Password: your_configured_password

# Kong API Gateway
# Access: http://localhost:8001 (Admin)
# Access: http://localhost:8000 (Proxy)
```

## Microsoft Fabric Integration

### 1. Semantic Model Creation

#### Connect to On-Premise Data

1. **Open Power BI Desktop**
2. **Get Data** > **Database** > **MySQL database**
3. **Server**: Your on-premise MySQL server
4. **Database**: data_platform
5. **Authentication**: Use gateway credentials

#### Create Semantic Models

```sql
-- Example semantic model for IoT data
CREATE VIEW semantic_iot_summary AS
SELECT 
    device_id,
    device_type,
    DATE(timestamp) as date,
    AVG(temperature) as avg_temperature,
    MAX(temperature) as max_temperature,
    MIN(temperature) as min_temperature,
    COUNT(*) as reading_count
FROM iot_readings
GROUP BY device_id, device_type, DATE(timestamp);
```

### 2. Power BI Workspace Setup

1. **Create Workspace**:
   - Open Power BI Service
   - Create new workspace
   - Set up workspace permissions

2. **Publish Semantic Models**:
   - Publish from Power BI Desktop
   - Configure refresh schedule
   - Set up row-level security

3. **Create Dashboards**:
   - Build interactive dashboards
   - Configure real-time data
   - Set up alerts and notifications

### 3. Data Synchronization

#### Configure Incremental Refresh

```json
{
  "refreshPolicy": {
    "type": "incremental",
    "incrementalRefreshPolicy": {
      "refreshType": "full",
      "incrementalGranularity": "day",
      "incrementalWindow": 30
    }
  }
}
```

#### Set Up Scheduled Refresh

1. **Power BI Service**:
   - Go to dataset settings
   - Configure refresh schedule
   - Set up gateway data sources

2. **On-Premises Data Gateway**:
   - Configure refresh schedules
   - Set up error notifications
   - Monitor refresh status

## Security Configuration

### 1. Network Security

```bash
# Configure firewall rules
sudo ufw allow 3306/tcp  # MySQL
sudo ufw allow 8086/tcp  # InfluxDB
sudo ufw allow 9000/tcp  # MinIO
sudo ufw allow 8000/tcp  # Windmill
sudo ufw allow 3000/tcp  # Grafana
sudo ufw allow 8585/tcp  # Open Metadata
```

### 2. Azure AD Integration

#### Configure Azure AD App Registration

1. **Create App Registration**:
   - Azure Portal > App registrations
   - Create new registration
   - Configure redirect URIs

2. **Set Up Authentication**:
   - Configure supported account types
   - Set up client secrets
   - Configure API permissions

3. **Integrate with Applications**:
   - Update application configurations
   - Test authentication flow

### 3. API Security

#### Kong API Gateway Configuration

```yaml
# Example Kong configuration
services:
  - name: mysql-api
    url: http://mysql:3306
    routes:
      - name: mysql-route
        paths:
          - /api/mysql
    plugins:
      - name: key-auth
      - name: rate-limiting
        config:
          minute: 100
```

## Monitoring and Maintenance

### 1. Health Monitoring

#### Prometheus Configuration

```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'mysql'
    static_configs:
      - targets: ['mysql:3306']
  
  - job_name: 'influxdb'
    static_configs:
      - targets: ['influxdb:8086']
  
  - job_name: 'windmill'
    static_configs:
      - targets: ['windmill:8000']
```

#### Grafana Dashboards

1. **Import Dashboards**:
   - MySQL monitoring dashboard
   - InfluxDB time-series dashboard
   - Windmill ETL monitoring
   - System resource monitoring

2. **Set Up Alerts**:
   - Database connection alerts
   - ETL job failure alerts
   - System resource alerts

### 2. Backup Strategy

#### Database Backups

```bash
# MySQL backup script
#!/bin/bash
DATE=$(date +%Y%m%d_%H%M%S)
docker exec data-platform-mysql mysqldump -u root -p$MYSQL_ROOT_PASSWORD data_platform > backup_$DATE.sql

# InfluxDB backup
docker exec data-platform-influxdb influx backup /backup/backup_$DATE

# MinIO backup
mc mirror minio/data /backup/minio_$DATE
```

#### Automated Backup Schedule

```bash
# Add to crontab
0 2 * * * /path/to/backup-script.sh
```

### 3. Performance Optimization

#### Database Optimization

```sql
-- MySQL optimization
OPTIMIZE TABLE iot_readings;
ANALYZE TABLE device_metadata;

-- Create indexes for common queries
CREATE INDEX idx_timestamp ON iot_readings(timestamp);
CREATE INDEX idx_device_id ON iot_readings(device_id);
```

#### Windmill ETL Optimization

```python
# Example optimized Windmill script
import pandas as pd
from sqlalchemy import create_engine

def process_iot_data():
    # Use chunked processing for large datasets
    engine = create_engine('mysql://user:pass@mysql:3306/data_platform')
    
    for chunk in pd.read_sql('SELECT * FROM iot_readings', engine, chunksize=10000):
        # Process chunk
        processed_chunk = chunk.groupby('device_id').agg({
            'temperature': ['mean', 'max', 'min'],
            'humidity': ['mean', 'max', 'min']
        })
        
        # Save processed data
        processed_chunk.to_sql('processed_iot_data', engine, if_exists='append')
```

## Troubleshooting

### Common Issues

#### 1. Database Connection Issues

```bash
# Check MySQL connectivity
docker exec data-platform-mysql mysql -u root -p -e "SHOW PROCESSLIST;"

# Check InfluxDB connectivity
curl -G http://localhost:8086/query --data-urlencode "q=SHOW DATABASES"
```

#### 2. Windmill ETL Issues

```bash
# Check Windmill logs
docker-compose logs windmill

# Check Windmill database
docker exec data-platform-windmill-db psql -U windmill -d windmill -c "SELECT * FROM jobs;"
```

#### 3. Microsoft Fabric Integration Issues

```bash
# Check On-Premises Data Gateway
# Windows: Check Windows Services
# Linux: Check systemd services

# Test gateway connectivity
# Use Power BI Gateway Configuration tool
```

### Performance Issues

#### 1. Slow Query Performance

```sql
-- Check slow queries
SHOW VARIABLES LIKE 'slow_query_log';
SHOW VARIABLES LIKE 'long_query_time';

-- Analyze query performance
EXPLAIN SELECT * FROM iot_readings WHERE device_id = 'device_001';
```

#### 2. ETL Performance

```python
# Monitor Windmill performance
import time

def monitor_etl_performance():
    start_time = time.time()
    # ETL process
    end_time = time.time()
    print(f"ETL took {end_time - start_time} seconds")
```

## Scaling Considerations

### 1. Horizontal Scaling

#### Database Scaling

```yaml
# MySQL read replicas
services:
  mysql-replica:
    image: mysql:8.0
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
    command: --read-only
```

#### Windmill Scaling

```yaml
# Multiple Windmill instances
services:
  windmill-1:
    image: windmilllabs/windmill:latest
    environment:
      BASE_URL: http://localhost:8000
    ports:
      - "8000:8000"
  
  windmill-2:
    image: windmilllabs/windmill:latest
    environment:
      BASE_URL: http://localhost:8001
    ports:
      - "8001:8000"
```

### 2. Load Balancing

#### Kong Load Balancer Configuration

```yaml
# Kong load balancer
services:
  - name: windmill-cluster
    url: http://windmill-1:8000
    routes:
      - name: windmill-route
        paths:
          - /api/windmill
    plugins:
      - name: upstream
        config:
          algorithm: round-robin
          targets:
            - target: windmill-1:8000
              weight: 50
            - target: windmill-2:8000
              weight: 50
```

## Conclusion

This on-premise deployment provides a robust, scalable data platform with Microsoft Fabric integration for advanced analytics. The hybrid approach ensures data sovereignty while leveraging cloud-based semantic modeling capabilities.

### Key Benefits
- **Data Sovereignty**: Complete control over data location
- **Security**: Enhanced security controls
- **Cost Control**: Predictable operational costs
- **Performance**: Optimized for local workloads
- **Compliance**: Easier regulatory compliance

### Next Steps
1. **Production Deployment**: Follow security hardening guidelines
2. **Monitoring Setup**: Configure comprehensive monitoring
3. **Backup Strategy**: Implement automated backup procedures
4. **Performance Tuning**: Optimize based on workload patterns
5. **Team Training**: Provide training on platform usage
